import os
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup


def scrape_ponisha_python_projects():
    # Ù…Ø³ÛŒØ± Ù¾ÙˆØ´Ù‡ data (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª Ø¨Ø³Ø§Ø²)
    data_dir = os.path.join(os.path.dirname(__file__), "data")
    os.makedirs(data_dir, exist_ok=True)
    output_file = os.path.join(data_dir, "ponisha_python_projects.xlsx")

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø±ÙˆØ±Ú¯Ø± (headless ÛŒØ¹Ù†ÛŒ Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ù¾Ù†Ø¬Ø±Ù‡)
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")

    # Ù…Ø³ÛŒØ± chromedriver (Ø¨Ø§ÛŒØ¯ Ù†ØµØ¨ Ø¨Ø§Ø´Ù‡ Ùˆ ØªÙˆÛŒ Ù‡Ù…ÛŒÙ† Ù…Ø³ÛŒØ± Ø¨Ø§Ø´Ù‡ ÛŒØ§ ØªÙˆÛŒ PATH)
    service = Service("chromedriver.exe")
    driver = webdriver.Chrome(service=service, options=chrome_options)

    # Ø¢Ø¯Ø±Ø³ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Python
    url = "https://ponisha.ir/search/projects?q=python"
    driver.get(url)
    time.sleep(3)

    # Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù„ÙˆØ¯ Ø´Ø¯Ù† Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
    for _ in range(5):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)

    # Ú¯Ø±ÙØªÙ† HTML
    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
    projects = soup.find_all("div", class_="project-card")  # ğŸ‘ˆ Ù…Ù…Ú©Ù†Ù‡ Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ù‡ Ø¢Ù¾Ø¯ÛŒØª Ø¨Ø´Ù‡

    data = []
    for i, project in enumerate(projects, 1):
        try:
            name = project.find("h2").get_text(strip=True)
        except:
            name = ""

        try:
            description = project.find("div", class_="description").get_text(strip=True)
        except:
            description = ""

        try:
            price = project.find("div", class_="budget").get_text(strip=True)
        except:
            price = ""

        try:
            time_left = project.find("div", class_="time-left").get_text(strip=True)
        except:
            time_left = ""

        try:
            skills = ", ".join([s.get_text(strip=True) for s in project.find_all("a", class_="skill")])
        except:
            skills = ""

        data.append({
            "Ø´Ù…Ø§Ø±Ù‡": i,
            "Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡": name,
            "ØªÙˆØ¶ÛŒØ­Ø§Øª Ù¾Ø±ÙˆÚ˜Ù‡": description,
            "Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)": price,
            "Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡": time_left,
            "Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²": skills
        })

    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø§Ú©Ø³Ù„
    df = pd.DataFrame(data)
    df.to_excel(output_file, index=False, engine="openpyxl")
    print(f"âœ… {len(data)} Ù¾Ø±ÙˆÚ˜Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ â†’ {output_file}")


if __name__ == "__main__":
    scrape_ponisha_python_projects()
